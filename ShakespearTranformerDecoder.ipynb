{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vADpv1bnBB8g"
      },
      "source": [
        "### Getting the shakspear data as a tensorflow dataset and converting it to simple text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "_sW9Or9GxoHP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "Sample_dataset = tfds.load(\"tiny_shakespeare\", split=\"train\", try_gcs=True)\n",
        "ds = tfds.as_dataframe(Sample_dataset)\n",
        "text = ds.head(1)['text'][0]\n",
        "text = ''.join([chr(x) for x in text])\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxjauW5T8t2h",
        "outputId": "58dfd41e-0655-45cd-969d-6d0379c083a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViO9hwlQ_T13",
        "outputId": "3843dc0e-ae6d-4260-c43a-2a6e270c88ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset: 1003854\n"
          ]
        }
      ],
      "source": [
        "print(\"length of dataset:\",len(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3bG8GIsA6rv"
      },
      "source": [
        "# finding what is the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSgPu-mAAH3w",
        "outputId": "5da09322-345a-4739-b9df-2c82f5d2c0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "vocab size: 65\n"
          ]
        }
      ],
      "source": [
        "vocab = sorted(list(set(text)))\n",
        "print(\"vocabulary:\",vocab)\n",
        "vocab_size = len(vocab)\n",
        "print(\"vocab size:\",vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seyPaBiqBBJA"
      },
      "source": [
        "# Tokenizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Q0DdKQA1-X",
        "outputId": "2216636b-790c-4f64-d4d7-7f9bb6b179ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenization dictionary: {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
            "detokenization dictionary: {0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
          ]
        }
      ],
      "source": [
        "tokenization_dict = {x:idx for idx,x in enumerate(vocab)}\n",
        "detokenization_dict = {idx:x for idx,x in enumerate(vocab)}\n",
        "encode = lambda s:[tokenization_dict[x] for x in s]\n",
        "decode = lambda i:[detokenization_dict[x] for x in i]\n",
        "print(\"tokenization dictionary:\",tokenization_dict)\n",
        "print(\"detokenization dictionary:\",detokenization_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsvzfCcAPvGA"
      },
      "source": [
        "# transforming into torch tensor and spliting to train-test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-TBbQldPIXA",
        "outputId": "e4d3d7b3-605d-496e-a7e9-e848b1ce267b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1003854]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text),dtype = torch.long)\n",
        "print(data.shape,data.dtype)\n",
        "print(data[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCQKqrlTP91R",
        "outputId": "d8503024-2b67-4fd8-f26a-6c64337548b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n",
            "test: tensor([21, 27, 10,  0, 32, 46, 39, 58,  1, 57, 46, 39, 50, 50,  1, 52, 53, 58,\n",
            "         1, 40, 43,  1, 51, 59, 41, 46,  1, 39, 51, 47, 57, 57, 10,  1, 37, 43,\n",
            "        58,  6,  1, 39, 57,  1, 58, 46, 43,  1, 51, 39, 58, 58, 43, 56,  0, 52,\n",
            "        53, 61,  1, 57, 58, 39, 52, 42, 57,  6,  1, 46, 43,  1, 61, 47, 50, 50,\n",
            "         1, 39, 60, 53, 47, 42,  1, 63, 53, 59, 56,  1, 39, 41, 41, 59, 57, 39,\n",
            "        58, 47, 53, 52, 11,  1, 46, 43,  1, 51])\n"
          ]
        }
      ],
      "source": [
        "train_data = data[:int(len(data)*0.9)]\n",
        "test_data = data[int(len(data)*0.9):]\n",
        "print(\"train:\",train_data[:100])\n",
        "print(\"test:\",test_data[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onF-_CbBR7cg"
      },
      "source": [
        "# creating a function that makes batches from the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci93qfsUR6op",
        "outputId": "f388365f-787b-4283-aae8-c12c7ff72963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['h', 'u', 'r', 'l', '!', ' ', 'd', 'r', 'u', 'n', 'k', ' ', 'a', 'l', 'l', ',', ' ', 'a', 'n', 'd', ' ', 'l', 'e', 'f', 't', ' ', 'n', 'o', ' ', 'f', 'r', 'i', 'e', 'n', 'd', 'l', 'y', ' ', 'd', 'r', 'o', 'p', '\\n', 'T', 'o', ' ', 'h', 'e', 'l', 'p', ' ', 'm', 'e', ' ', 'a', 'f', 't', 'e', 'r', '?', ' ', 'I', ' ', 'w', 'i', 'l', 'l', ' ', 'k', 'i', 's', 's', ' ', 't', 'h', 'y', ' ', 'l', 'i', 'p', 's', ';', '\\n', 'H', 'a', 'p', 'l', 'y', ' ', 's', 'o', 'm', 'e', ' ', 'p', 'o', 'i', 's', 'o', 'n', ' ', 'y', 'e', 't', ' ', 'd', 'o', 't', 'h', ' ', 'h', 'a', 'n', 'g', ' ', 'o', 'n', ' ', 't', 'h', 'e', 'm', ',', '\\n', 'T', 'o', ' ', 'm', 'a', 'k', 'e', ' ', 'd', 'i', 'e', ' ', 'w', 'i', 't', 'h', ' ', 'a', ' ', 'r', 'e', 's', 't', 'o', 'r', 'a'] ['u', 'r', 'l', '!', ' ', 'd', 'r', 'u', 'n', 'k', ' ', 'a', 'l', 'l', ',', ' ', 'a', 'n', 'd', ' ', 'l', 'e', 'f', 't', ' ', 'n', 'o', ' ', 'f', 'r', 'i', 'e', 'n', 'd', 'l', 'y', ' ', 'd', 'r', 'o', 'p', '\\n', 'T', 'o', ' ', 'h', 'e', 'l', 'p', ' ', 'm', 'e', ' ', 'a', 'f', 't', 'e', 'r', '?', ' ', 'I', ' ', 'w', 'i', 'l', 'l', ' ', 'k', 'i', 's', 's', ' ', 't', 'h', 'y', ' ', 'l', 'i', 'p', 's', ';', '\\n', 'H', 'a', 'p', 'l', 'y', ' ', 's', 'o', 'm', 'e', ' ', 'p', 'o', 'i', 's', 'o', 'n', ' ', 'y', 'e', 't', ' ', 'd', 'o', 't', 'h', ' ', 'h', 'a', 'n', 'g', ' ', 'o', 'n', ' ', 't', 'h', 'e', 'm', ',', '\\n', 'T', 'o', ' ', 'm', 'a', 'k', 'e', ' ', 'd', 'i', 'e', ' ', 'w', 'i', 't', 'h', ' ', 'a', ' ', 'r', 'e', 's', 't', 'o', 'r', 'a', 't']\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(11111)\n",
        "batch_size = 128\n",
        "seq_len = 150\n",
        "\n",
        "def get_batch(Train = True):\n",
        "  data = train_data if Train else test_data\n",
        "  idxs = torch.randint(low =0,high = len(data)-seq_len-1,size = (batch_size,))\n",
        "  Xs = torch.stack([data[i:i+seq_len] for i in idxs])\n",
        "  Ys = torch.stack([data[i+1:i+seq_len+1] for i in idxs])\n",
        "  return Xs,Ys\n",
        "Xs,Ys = get_batch()\n",
        "print(decode(Xs[0].numpy()),decode(Ys[0].numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsZuEr6KSlW-"
      },
      "source": [
        "# positional embbeding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "--wzt9DRSp7l"
      },
      "outputs": [],
      "source": [
        "embed_size = 128\n",
        "import math\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "\n",
        "        position = torch.arange(max_len,device = device).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2,device = device) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(1, max_len, d_model)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term).to(device)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term).to(device)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
        "        \"\"\"\n",
        "        #print(self.pe[:,:x.shape[-2]].shape)\n",
        "        x = x + self.pe[:,:x.shape[-2]]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo24iO0wYnfG",
        "outputId": "8ffe9fe1-fc96-4783-a35b-e06ea522c224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2443, -0.7473, -0.5315,  ..., -0.4596, -1.3047, -0.0761],\n",
            "        [ 0.2443, -0.7473, -0.5315,  ..., -0.4596, -1.3047, -0.0761],\n",
            "        [ 0.8729, -0.9268, -2.4263,  ...,  0.5712, -0.0637, -2.9809],\n",
            "        ...,\n",
            "        [-0.3287,  1.1828,  1.3727,  ...,  1.4871,  0.0398, -0.9164],\n",
            "        [ 0.0116,  0.8708,  1.5919,  ...,  0.3623,  0.1317,  0.6312],\n",
            "        [-0.0321, -0.1118,  1.0336,  ...,  0.1925,  0.6394, -0.6297]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([[ 0.2443,  0.2527, -0.5315,  ...,  0.5404, -1.3047,  0.9239],\n",
            "        [ 1.0857, -0.2070,  0.2302,  ...,  0.5404, -1.3046,  0.9239],\n",
            "        [ 1.7822, -1.3430, -1.4392,  ...,  1.5712, -0.0635, -1.9809],\n",
            "        ...,\n",
            "        [ 0.2803,  0.3897,  2.3707,  ...,  2.4869,  0.0568,  0.0834],\n",
            "        [-0.3268, -0.0702,  2.1912,  ...,  1.3621,  0.1488,  1.6311],\n",
            "        [-1.0067, -0.3356,  0.8120,  ...,  1.1923,  0.6566,  0.3701]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "embed = nn.Embedding(vocab_size,embed_size)\n",
        "pos_embed = PositionalEncoding(embed_size,seq_len)\n",
        "Xs,_ = get_batch()\n",
        "embeded = embed(Xs)\n",
        "final = pos_embed(embeded)\n",
        "print(embeded[0])\n",
        "print(final[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtXQOVHYDrN"
      },
      "source": [
        "# self attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "PBjC0u4VXf0H"
      },
      "outputs": [],
      "source": [
        "class AttentionHead(nn.Module):\n",
        "\n",
        "  def __init__(self,head_size,input_size):\n",
        "    super().__init__()\n",
        "    self.query_layer = nn.Linear(input_size,head_size)\n",
        "    self.key_layer = nn.Linear(input_size,head_size)\n",
        "    self.value_layer = nn.Linear(input_size,head_size)\n",
        "    self.register_buffer('tril',torch.tril(torch.ones(seq_len,seq_len)))\n",
        "\n",
        "  def forward(self,x):\n",
        "    channel_size = x.shape[-1]\n",
        "    query = self.query_layer(x)\n",
        "    key = self.key_layer(x)\n",
        "    attention_matrix = query @ torch.transpose(key,-1,-2) * (channel_size ** -0.5)\n",
        "    masked_attention = attention_matrix.masked_fill(self.tril[:x.shape[-2],:x.shape[-2]] == 0, float('-inf'))\n",
        "    final_matrix = F.softmax(masked_attention,dim = -1)\n",
        "    value = self.value_layer(x)\n",
        "    out = final_matrix @ value\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_61BeVGlTWs",
        "outputId": "eaa7cfae-6d41-4ace-b7cf-71b59c016c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n",
            "torch.Size([128, 150, 128])\n"
          ]
        }
      ],
      "source": [
        "head_size = embed_size\n",
        "print(head_size)\n",
        "embed = nn.Embedding(vocab_size,embed_size)\n",
        "pos_embed = PositionalEncoding(embed_size,seq_len)\n",
        "Xs,_ = get_batch()\n",
        "embeded = embed(Xs)\n",
        "final = pos_embed(embeded)\n",
        "Attention = AttentionHead(head_size,embed_size)\n",
        "att = Attention(final)\n",
        "print(att.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTzqGLdgovIP"
      },
      "source": [
        "# Multi-Headed-self-Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "N8AM7Lpqo5Fg"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "  def __init__(self,num_heads,head_size,input_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([AttentionHead(head_size,input_size) for i in range(num_heads)])\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = torch.cat([h(x) for h in self.heads],dim = -1)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGXkK4y-pkO2",
        "outputId": "22ae9dc3-a390-48f9-cc02-46710f23c5f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 150, 512])\n"
          ]
        }
      ],
      "source": [
        "head_size = embed_size\n",
        "embed = nn.Embedding(vocab_size,embed_size).to(device)\n",
        "pos_embed = PositionalEncoding(embed_size,seq_len).to(device)\n",
        "Xs,_ = get_batch()\n",
        "embeded = embed(Xs.to(device))\n",
        "final = pos_embed(embeded)\n",
        "MHAttention = MultiHeadedAttention(num_heads = 4,head_size = head_size,input_size = embed_size).to(device)\n",
        "att = MHAttention(final)\n",
        "print(att.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT369KORCtUw"
      },
      "source": [
        "# Layer Norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "fG-yZX5BCs9Y"
      },
      "outputs": [],
      "source": [
        "class LayerNorm1d: # (used to be BatchNorm1d)\n",
        "  \n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim,device = device)\n",
        "    self.beta = torch.zeros(dim,device = device)\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    xmean = x.mean(1, keepdim=True) # batch mean\n",
        "    xvar = x.var(1, keepdim=True) # batch variance\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoIEIbZlrQLm"
      },
      "source": [
        "# Decoder-only-Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "qP2T43lDrVkt"
      },
      "outputs": [],
      "source": [
        "class DecoderOnlyBlock(nn.Module):\n",
        "  def __init__(self,num_heads,head_size,input_size,output_size):\n",
        "    super().__init__()\n",
        "    self.ff = nn.Sequential(nn.Linear(num_heads*head_size,4*output_size),nn.ReLU(),nn.Linear(4*output_size,output_size))\n",
        "    self.MHA = MultiHeadedAttention(num_heads,head_size,input_size)\n",
        "    self.lnl = LayerNorm1d(num_heads*head_size)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = x + self.MHA(self.lnl(x))\n",
        "    out = out + self.ff(self.lnl(out))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANk76NJ-IYcn",
        "outputId": "5f18f22e-c8e4-4c64-c54f-ad4221542fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 150, 128])\n"
          ]
        }
      ],
      "source": [
        "head_size = embed_size\n",
        "embed = nn.Embedding(vocab_size,embed_size).to(device)\n",
        "pos_embed = PositionalEncoding(embed_size,seq_len).to(device)\n",
        "Xs,_ = get_batch()\n",
        "embeded = embed(Xs.to(device))\n",
        "final = pos_embed(embeded)\n",
        "DEC_BLOCK = DecoderOnlyBlock(num_heads = 4,head_size = head_size//4,input_size = embed_size,output_size =embed_size).to(device)\n",
        "att = DEC_BLOCK(final)\n",
        "print(att.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su9DRZmDL_0E"
      },
      "source": [
        "# Decoder only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "wxF78fIwL-p1"
      },
      "outputs": [],
      "source": [
        "class DecoderOnly(nn.Module):\n",
        "  def __init__(self,num_blocks,num_heads,head_size,block_input_size,block_output_size,vocab_size,embed_size,seq_len):\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(vocab_size,embed_size)\n",
        "    self.pos_embed = PositionalEncoding(embed_size,seq_len)\n",
        "    self.dec_block1 = DecoderOnlyBlock(num_heads = num_heads,head_size = head_size,input_size = block_input_size,output_size =block_output_size)\n",
        "    self.dec_block2 = DecoderOnlyBlock(num_heads = num_heads,head_size = head_size,input_size = block_input_size,output_size =block_output_size)\n",
        "    self.dec_block3 = DecoderOnlyBlock(num_heads = num_heads,head_size = head_size,input_size = block_input_size,output_size =block_output_size)\n",
        "    self.dec_block4 = DecoderOnlyBlock(num_heads = num_heads,head_size = head_size,input_size = block_input_size,output_size =block_output_size)\n",
        "    self.L = nn.Linear(block_output_size,vocab_size)\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.embed(x)\n",
        "    out = self.pos_embed(out)\n",
        "    out = self.dec_block1(out)\n",
        "    out = self.dec_block2(out)\n",
        "    out = self.dec_block3(out)\n",
        "    out = self.dec_block4(out)\n",
        "    out = self.L(out)\n",
        "    return out\n",
        "\n",
        "  def generate(self,context,num_chars):\n",
        "    print(context)\n",
        "    for i in range(num_chars):\n",
        "      trimmed_context = context[-seq_len:]\n",
        "      next_char = torch.argmax(self.forward(trimmed_context),dim = -1)[-1][-1]\n",
        "      context = torch.cat((context,torch.unsqueeze(next_char,0)),dim = -1)\n",
        "    return context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s0Tv0HE8jOh",
        "outputId": "b98281f0-3005-4077-94e8-b5dfeb1ae811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 150, 65])\n"
          ]
        }
      ],
      "source": [
        "head_size = embed_size\n",
        "Xs,Ys = get_batch()\n",
        "DEC = DecoderOnly(num_blocks = 10, num_heads = 16,head_size = head_size//16,block_input_size = embed_size,block_output_size = embed_size,vocab_size=vocab_size,embed_size = embed_size,seq_len = seq_len).to(device)\n",
        "out = DEC(Xs.to(device))\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1DbpSIVJe_D",
        "outputId": "5f979571-39bf-4f80-f40d-8b7f8089f638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([53, 61,  1, 51, 43,  1, 39, 50, 47, 60, 43,  6,  0, 35, 46, 43, 56, 43,\n",
            "         1, 21,  1, 57, 46, 39, 50, 50,  1, 49, 52, 43, 43, 50,  1, 58, 53,  1,\n",
            "        46, 47, 51,  1, 58, 46, 39, 58,  1, 57, 50, 43, 61,  1, 51, 63,  1, 44,\n",
            "        39, 58, 46, 43, 56,  2,  0,  0, 23, 21, 26, 19,  1, 20, 17, 26, 30, 37,\n",
            "         1, 34, 21, 10,  0, 27,  1, 15, 50, 47, 44, 44, 53, 56, 42,  6,  1, 46,\n",
            "        53, 61,  1, 58, 46, 63,  1, 61, 53, 56, 42, 57,  1, 56, 43, 60, 47, 60,\n",
            "        43,  1, 51, 63,  1, 46, 43, 39, 56, 58,  2,  0,  0, 37, 27, 30, 23, 10,\n",
            "         0, 20, 43, 52, 56, 63,  1, 53, 44,  1, 24, 39, 52, 41, 39, 57, 58, 43,\n",
            "        56,  6,  1, 56, 43, 57], device='cuda:0')\n",
            "tensor([53, 61,  1, 51, 43,  1, 39, 50, 47, 60, 43,  6,  0, 35, 46, 43, 56, 43,\n",
            "         1, 21,  1, 57, 46, 39, 50, 50,  1, 49, 52, 43, 43, 50,  1, 58, 53,  1,\n",
            "        46, 47, 51,  1, 58, 46, 39, 58,  1, 57, 50, 43, 61,  1, 51, 63,  1, 44,\n",
            "        39, 58, 46, 43, 56,  2,  0,  0, 23, 21, 26, 19,  1, 20, 17, 26, 30, 37,\n",
            "         1, 34, 21, 10,  0, 27,  1, 15, 50, 47, 44, 44, 53, 56, 42,  6,  1, 46,\n",
            "        53, 61,  1, 58, 46, 63,  1, 61, 53, 56, 42, 57,  1, 56, 43, 60, 47, 60,\n",
            "        43,  1, 51, 63,  1, 46, 43, 39, 56, 58,  2,  0,  0, 37, 27, 30, 23, 10,\n",
            "         0, 20, 43, 52, 56, 63,  1, 53, 44,  1, 24, 39, 52, 41, 39, 57, 58, 43,\n",
            "        56,  6,  1, 56, 43, 57, 51, 35, 52, 48,  9, 16, 51, 35, 52, 48,  9, 16,\n",
            "        51, 35, 52, 48,  9, 16, 51, 35], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "Xs,_ = get_batch()\n",
        "char_seq = Xs[0].to(device)\n",
        "print(DEC.generate(char_seq,20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahKk-WjEAXNH"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOFbIniXSKAH"
      },
      "source": [
        "we shall add weights to the letters because the data is not ditributed equally, e.g: there are far more spaces than 'z's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPD-PYhFAZt3",
        "outputId": "7cac3cd6-0f19-4a65-fbf1-d897a97b2fc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6.5257e-04, 2.3451e-04, 5.0424e-03, 1.0000e+00, 4.6346e-01, 2.3900e-03,\n",
            "        1.0625e-03, 5.5106e-03, 2.0426e-03, 9.9551e-02, 1.7004e-03, 3.4951e-03,\n",
            "        4.6168e-03, 2.1092e-03, 4.2813e-03, 3.3181e-03, 4.9932e-03, 2.3882e-03,\n",
            "        5.4992e-03, 4.5902e-03, 4.0143e-03, 1.5481e-03, 1.7951e-02, 6.2236e-03,\n",
            "        3.2422e-03, 4.0529e-03, 2.8233e-03, 2.7457e-03, 6.9915e-03, 2.2222e-02,\n",
            "        2.8920e-03, 2.9849e-03, 2.2739e-03, 3.6332e-03, 9.7518e-03, 3.5096e-03,\n",
            "        3.6775e-02, 5.5993e-03, 2.8525e-02, 5.1575e-04, 1.5592e-03, 1.2435e-03,\n",
            "        7.6210e-04, 3.5289e-04, 1.2336e-03, 1.3876e-03, 5.4138e-04, 5.9043e-04,\n",
            "        1.1520e-02, 2.1675e-03, 7.3047e-04, 9.7671e-04, 5.6344e-04, 4.5471e-04,\n",
            "        1.6052e-03, 1.1875e-02, 5.5939e-04, 5.5459e-04, 4.5015e-04, 8.5735e-04,\n",
            "        2.0147e-03, 1.1529e-03, 1.3278e-02, 1.0343e-03, 1.7636e-02])\n",
            "cuda:0\n",
            "cuda:0\n",
            "torch.Size([128, 150])\n",
            "torch.Size([128, 150, 65])\n",
            "tensor(4.5190, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "weights = torch.tensor([text.count(x)**-0.7 for x in vocab])\n",
        "print(weights)\n",
        "Ys = Ys.to(device)\n",
        "flatYs = torch.flatten(Ys,0,1)\n",
        "flatout = torch.flatten(out,0,1)\n",
        "print(flatout.device)\n",
        "print(flatYs.device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=weights).to(device)\n",
        "print(Ys.shape)\n",
        "print(out.shape)\n",
        "loss = loss_fn(flatout, flatYs)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "EYkw_8Ng7vq_"
      },
      "outputs": [],
      "source": [
        "def get_loss(logits,labels,fn):\n",
        "  return fn(torch.flatten(logits,0,1), torch.flatten(labels,0,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Enyvz-9lPP",
        "outputId": "edc6f579-347b-496a-a8f3-cd234962a3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.3998, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(get_loss(out,Ys,torch.nn.CrossEntropyLoss()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "vDhddyEKBbi9"
      },
      "outputs": [],
      "source": [
        "def eval(model,loss_fn,Train = False):\n",
        "  Xs,Ys = get_batch(Train = Train)\n",
        "  return get_loss(model(Xs.to(device)),Ys.to(device),loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB_QY0c2D608",
        "outputId": "6ba62553-87db-47a9-ceb4-7e992884a122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.4519, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(eval(DEC,loss_fn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "3cVOeaXg908G"
      },
      "outputs": [],
      "source": [
        "def train_step(model,loss_fn,optimizer):\n",
        "  Xs,Ys = get_batch()\n",
        "  loss = get_loss(model(Xs.to(device)),Ys.to(device),loss_fn)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGUtWpfJE1Hc",
        "outputId": "c9a9553e-5b5b-4470-86d8-b5662e9343a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "opt = torch.optim.Adagrad(DEC.parameters())\n",
        "d = DEC.to(device)\n",
        "print(next(d.parameters()).device)\n",
        "train_step(d,loss_fn,opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "VbbkELknGRJT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def train_loop(model,loss_fn,optimizer,epochs,epoch_length = 1000):\n",
        "  for i in range(epochs):\n",
        "    start_time = time.time()\n",
        "    for j in range(epoch_length):\n",
        "      train_step(model,loss_fn,optimizer)\n",
        "    print(\"epoch: \",i,\" train loss: \", eval(model,loss_fn,Train = True),\" test loss: \", eval(model,loss_fn), \" time of execution:\",(\"--- %s seconds ---\" % (time.time() - start_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Liy5oDmMHScj",
        "outputId": "88ca13e7-0b88-4fe0-c3cb-a609ab148f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0  train loss:  tensor(0.9968, device='cuda:0', grad_fn=<NllLossBackward0>)  test loss:  tensor(1.2496, device='cuda:0', grad_fn=<NllLossBackward0>)  time of execution: --- 237.2575409412384 seconds ---\n",
            "epoch:  1  train loss:  tensor(0.8435, device='cuda:0', grad_fn=<NllLossBackward0>)  test loss:  tensor(1.1251, device='cuda:0', grad_fn=<NllLossBackward0>)  time of execution: --- 238.26756358146667 seconds ---\n",
            "epoch:  2  train loss:  tensor(0.7991, device='cuda:0', grad_fn=<NllLossBackward0>)  test loss:  tensor(1.0506, device='cuda:0', grad_fn=<NllLossBackward0>)  time of execution: --- 238.4426748752594 seconds ---\n"
          ]
        }
      ],
      "source": [
        "train_loop(DEC,loss_fn,opt,epochs = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7UUOSSxHtvj",
        "outputId": "c4d95295-b42b-4509-b221-be459aef6e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1, 57, 53, 52,  6,  1, 39, 52, 42,  1, 46, 53, 51, 43, 50, 63,  1, 47,\n",
            "        52,  1, 58, 46, 63,  1, 42, 56, 47, 44, 58, 11,  0, 30, 47, 42, 42, 50,\n",
            "        47, 52, 45,  1, 41, 53, 52, 44, 43, 57, 57, 47, 53, 52,  1, 44, 47, 52,\n",
            "        42, 57,  1, 40, 59, 58,  1, 56, 47, 42, 42, 50, 47, 52, 45,  1, 57, 46,\n",
            "        56, 47, 44, 58,  8,  0,  0, 30, 27, 25, 17, 27, 10,  0, 32, 46, 43, 52,\n",
            "         1, 54, 50, 39, 47, 52, 50, 63,  1, 49, 52, 53, 61,  1, 51, 63,  1, 46,\n",
            "        43, 39, 56, 58,  5, 57,  1, 42, 43, 39, 56,  1, 50, 53, 60, 43,  1, 47,\n",
            "        57,  1, 57, 43, 58,  0, 27, 52,  1, 58, 46, 43,  1, 44, 39, 47, 56,  1,\n",
            "        42, 39, 59, 45, 46, 58], device='cuda:0')\n",
            "tensor([ 1, 57, 53, 52,  6,  1, 39, 52, 42,  1, 46, 53, 51, 43, 50, 63,  1, 47,\n",
            "        52,  1, 58, 46, 63,  1, 42, 56, 47, 44, 58, 11,  0, 30, 47, 42, 42, 50,\n",
            "        47, 52, 45,  1, 41, 53, 52, 44, 43, 57, 57, 47, 53, 52,  1, 44, 47, 52,\n",
            "        42, 57,  1, 40, 59, 58,  1, 56, 47, 42, 42, 50, 47, 52, 45,  1, 57, 46,\n",
            "        56, 47, 44, 58,  8,  0,  0, 30, 27, 25, 17, 27, 10,  0, 32, 46, 43, 52,\n",
            "         1, 54, 50, 39, 47, 52, 50, 63,  1, 49, 52, 53, 61,  1, 51, 63,  1, 46,\n",
            "        43, 39, 56, 58,  5, 57,  1, 42, 43, 39, 56,  1, 50, 53, 60, 43,  1, 47,\n",
            "        57,  1, 57, 43, 58,  0, 27, 52,  1, 58, 46, 43,  1, 44, 39, 47, 56,  1,\n",
            "        42, 39, 59, 45, 46, 58,  1, 61, 47, 52, 45, 46,  8,  0,  0, 22, 33, 24,\n",
            "        21, 17, 32, 10,  0, 35, 46, 47], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "Xs,_ = get_batch()\n",
        "char_seq = Xs[0].to(device)\n",
        "print(DEC.generate(char_seq,20))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"output:\\n\"+''.join(decode(DEC.generate(char_seq,150).cpu().numpy()))+'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5dKV94uG8Le",
        "outputId": "682b1fd9-5a94-4d24-d680-fa12ef3547d8"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1, 57, 53, 52,  6,  1, 39, 52, 42,  1, 46, 53, 51, 43, 50, 63,  1, 47,\n",
            "        52,  1, 58, 46, 63,  1, 42, 56, 47, 44, 58, 11,  0, 30, 47, 42, 42, 50,\n",
            "        47, 52, 45,  1, 41, 53, 52, 44, 43, 57, 57, 47, 53, 52,  1, 44, 47, 52,\n",
            "        42, 57,  1, 40, 59, 58,  1, 56, 47, 42, 42, 50, 47, 52, 45,  1, 57, 46,\n",
            "        56, 47, 44, 58,  8,  0,  0, 30, 27, 25, 17, 27, 10,  0, 32, 46, 43, 52,\n",
            "         1, 54, 50, 39, 47, 52, 50, 63,  1, 49, 52, 53, 61,  1, 51, 63,  1, 46,\n",
            "        43, 39, 56, 58,  5, 57,  1, 42, 43, 39, 56,  1, 50, 53, 60, 43,  1, 47,\n",
            "        57,  1, 57, 43, 58,  0, 27, 52,  1, 58, 46, 43,  1, 44, 39, 47, 56,  1,\n",
            "        42, 39, 59, 45, 46, 58], device='cuda:0')\n",
            "output:\n",
            " son, and homely in thy drift;\n",
            "Riddling confession finds but riddling shrift.\n",
            "\n",
            "ROMEO:\n",
            "Then plainly know my heart's dear love is set\n",
            "On the fair daught wingh.\n",
            "\n",
            "JULIET:\n",
            "Whill givengut willl, wingh spour win benger's.\n",
            "AUF shat sour Mand Jull's justy Palingaces,\n",
            "For Dus sollive ston ther there wingung w\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zRS89WgQvgY",
        "outputId": "737eea75-d039-4bd3-82bf-1153cc5eed30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1, 57, 53, 52,  6,  1, 39, 52, 42,  1, 46, 53, 51, 43, 50, 63,  1, 47,\n",
            "        52,  1, 58, 46, 63,  1, 42, 56, 47, 44, 58, 11,  0, 30, 47, 42, 42, 50,\n",
            "        47, 52, 45,  1, 41, 53, 52, 44, 43, 57, 57, 47, 53, 52,  1, 44, 47, 52,\n",
            "        42, 57,  1, 40, 59, 58,  1, 56, 47, 42, 42, 50, 47, 52, 45,  1, 57, 46,\n",
            "        56, 47, 44, 58,  8,  0,  0, 30, 27, 25, 17, 27, 10,  0, 32, 46, 43, 52,\n",
            "         1, 54, 50, 39, 47, 52, 50, 63,  1, 49, 52, 53, 61,  1, 51, 63,  1, 46,\n",
            "        43, 39, 56, 58,  5, 57,  1, 42, 43, 39, 56,  1, 50, 53, 60, 43,  1, 47,\n",
            "        57,  1, 57, 43, 58,  0, 27, 52,  1, 58, 46, 43,  1, 44, 39, 47, 56,  1,\n",
            "        42, 39, 59, 45, 46, 58], device='cuda:0')\n",
            "output:\n",
            " son, and homely in thy drift;\n",
            "Riddling confession finds but riddling shrift.\n",
            "\n",
            "ROMEO:\n",
            "Then plainly know my heart's dear love is set\n",
            "On the fair daught wingh.\n",
            "\n",
            "JULIET:\n",
            "Whill givengut willl, wingh spour win benger's.\n",
            "AUF shat sour Mand Jull's justy Palingaces,\n",
            "For Dus sollive ston ther there wingung w\n",
            "\n",
            "original:\n",
            " son, and homely in thy drift;\n",
            "Riddling confession finds but riddling shrift.\n",
            "\n",
            "ROMEO:\n",
            "Then plainly know my heart's dear love is set\n",
            "On the fair daught\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"output:\\n\"+''.join(decode(DEC.generate(char_seq,150).cpu().numpy()))+'\\n')\n",
        "print(\"original:\\n\"+''.join(decode(char_seq.cpu().numpy()))+'\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}